# -*- coding: utf-8 -*-
"""Medical Image Segmentation for Cardiac Analysis Using U-Net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TX1MAFSttFYT8S0TdaCIJL4QqMf51KOY

# **Medical Image Segmentation for Cardiac Analysis Using U-Net**

## **Shah Wali Ullah Baig**

This project focuses on medical image segmentation, specifically for cardiac analysis. The objective is to develop a robust deep learning model that can accurately segment and identify regions of interest in cardiac MRI images. The primary challenge addressed by this project is the precise delineation of the myocardium in cardiac images, which plays a crucial role in various diagnostic and research applications.
"""

# from google.colab import drive
# # Mount Google Drive
# drive.mount('/content/drive')

# # Install necessary packages
# !pip install nibabel
# !pip install scikit-image

import os
import zipfile
import numpy as np
import nibabel as nib
from skimage import transform
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import layers, models
import glob

# Set the path to your dataset in Google Drive
zip_file_path = '/content/drive/MyDrive/DataSets/Training.zip'
extracted_folder_path = '/content/drive/MyDrive/DataSets/Training/'

# Check if the dataset is already extracted, if not, extract it
if not os.path.exists(extracted_folder_path):
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extracted_folder_path)

# Function to load and preprocess Nifti images and masks
def load_data(folder):
    images, masks = [], []

    # Use glob to get all relevant files
    file_pattern = os.path.join(folder, '*/*_frame01.nii.gz')
    file_list = glob.glob(file_pattern)

    for image_path in file_list:
        print(f"Loading image: {image_path}")

        # Derive mask path from image path
        mask_path = image_path.replace("_frame01.nii.gz", "_frame01_gt.nii.gz")
        print(f"Loading mask: {mask_path}")

        # Load and preprocess images
        image_data = nib.load(image_path).get_fdata()

        # If there are multiple frames, consider the first frame (adjust as needed)
        image = image_data[:, :, 0]
        image = transform.resize(image, (256, 256))  # Resize to your desired input shape
        images.append(image)

        # Load and preprocess masks
        mask_data = nib.load(mask_path).get_fdata()

        # If there are multiple frames, consider the first frame (adjust as needed)
        mask = mask_data[:, :, 0]
        mask = transform.resize(mask, (256, 256))  # Resize to your desired output shape
        mask = (mask > 0.5).astype(np.uint8)  # Binarize the mask
        masks.append(mask)

    return np.array(images), np.array(masks)


# Load data
X, y = load_data(extracted_folder_path)

# Print some information to diagnose the issue
print(f"Number of patients: {len(os.listdir(extracted_folder_path))}")
print(f"Number of files loaded: {len(X)}")

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

import tensorflow as tf
from tensorflow.keras import layers, models

def unet_model(input_shape=(256, 256, 1)):
    inputs = tf.keras.Input(shape=input_shape)

    # Encoder
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)

    # Bottleneck
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)

    # Decoder
    up5 = layers.UpSampling2D(size=(2, 2))(conv4)
    up5 = layers.Conv2D(256, 2, activation='relu', padding='same')(up5)
    merge5 = layers.concatenate([conv3, up5], axis=3)
    conv5 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge5)
    conv5 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv5)

    up6 = layers.UpSampling2D(size=(2, 2))(conv5)
    up6 = layers.Conv2D(128, 2, activation='relu', padding='same')(up6)
    merge6 = layers.concatenate([conv2, up6], axis=3)
    conv6 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge6)
    conv6 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv6)

    up7 = layers.UpSampling2D(size=(2, 2))(conv6)
    up7 = layers.Conv2D(64, 2, activation='relu', padding='same')(up7)
    merge7 = layers.concatenate([conv1, up7], axis=3)
    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge7)
    conv7 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv7)

    # Output layer
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv7)

    model = models.Model(inputs=inputs, outputs=outputs)
    return model

# Create the U-Net model
model = unet_model()

# Print the model summary
model.summary()


# Example usage
input_shape = (256, 256, 1)  # Adjust based on your image dimensions
model = unet_model(input_shape)

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model
evaluation = model.evaluate(X_test, y_test)
print(f"Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}")

import matplotlib.pyplot as plt

# Function to plot images and masks
def plot_images(images, masks_true, masks_pred, num_samples=5):
    plt.figure(figsize=(15, 4 * num_samples))
    for i in range(num_samples):
        # Original Image
        plt.subplot(num_samples, 3, i * 3 + 1)
        plt.imshow(images[i, :, :], cmap='gray')  # Assuming the images are 3D (height, width, channels)
        plt.title('Original Image')

        # Ground Truth Mask
        plt.subplot(num_samples, 3, i * 3 + 2)
        plt.imshow(masks_true[i, :, :], cmap='gray')  # Assuming the masks are 3D (height, width, channels)
        plt.title('Ground Truth Mask')

        # Predicted Mask
        plt.subplot(num_samples, 3, i * 3 + 3)
        plt.imshow(masks_pred[i, :, :] > 0.5, cmap='gray')  # Adjust the threshold here
        plt.title('Predicted Mask')


    plt.tight_layout()
    plt.show()

# Make predictions on the test set
predictions = model.predict(X_test)

# Display some results
num_samples_to_display = 5
plot_images(X_test[:num_samples_to_display, :, :], y_test[:num_samples_to_display, :, :], predictions[:num_samples_to_display, :, :])

